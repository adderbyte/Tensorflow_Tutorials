{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Lukman copyright \n",
    "# MIT Licence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# for data frame analysis\n",
    "import pandas as pd \n",
    "\n",
    "# for mathematical operations\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "# matplotlib library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# for use of tensorflow\n",
    "import tensorflow as tf\n",
    "#from tensorflow.nn.rnn import *\n",
    "from tensorflow.python.ops  import *\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE MODEL IS FOR EDUCATION PURPOSES ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable eager executinon\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data set\n",
    "illustration = pd.read_csv('illustration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>primary_use_Education</th>\n",
       "      <th>primary_use_Entertainment/public assembly</th>\n",
       "      <th>primary_use_Food sales and service</th>\n",
       "      <th>primary_use_Healthcare</th>\n",
       "      <th>...</th>\n",
       "      <th>primary_use_Utility</th>\n",
       "      <th>site_id_2</th>\n",
       "      <th>site_id_6</th>\n",
       "      <th>site_id_7</th>\n",
       "      <th>site_id_9</th>\n",
       "      <th>site_id_10</th>\n",
       "      <th>site_id_11</th>\n",
       "      <th>site_id_13</th>\n",
       "      <th>site_id_14</th>\n",
       "      <th>site_id_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-138.151378</td>\n",
       "      <td>21958</td>\n",
       "      <td>-10.64683</td>\n",
       "      <td>-0.056432</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meter_reading  square_feet  air_temperature  dew_temperature  month  day  \\\n",
       "1    -138.151378        21958        -10.64683        -0.056432      1    1   \n",
       "\n",
       "   primary_use_Education  primary_use_Entertainment/public assembly  \\\n",
       "1                      0                                          0   \n",
       "\n",
       "   primary_use_Food sales and service  primary_use_Healthcare  ...  \\\n",
       "1                                   0                       0  ...   \n",
       "\n",
       "   primary_use_Utility  site_id_2  site_id_6  site_id_7  site_id_9  \\\n",
       "1                    1          1          0          0          0   \n",
       "\n",
       "   site_id_10  site_id_11  site_id_13  site_id_14  site_id_15  \n",
       "1           0           0           0           0           0  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view data set\n",
    "# AIM IS TO PREDICT METER READING \n",
    "illustration[1:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meter_reading                                False\n",
       "square_feet                                  False\n",
       "air_temperature                              False\n",
       "dew_temperature                              False\n",
       "month                                        False\n",
       "day                                          False\n",
       "primary_use_Education                        False\n",
       "primary_use_Entertainment/public assembly    False\n",
       "primary_use_Food sales and service           False\n",
       "primary_use_Healthcare                       False\n",
       "primary_use_Lodging/residential              False\n",
       "primary_use_Manufacturing/industrial         False\n",
       "primary_use_Office                           False\n",
       "primary_use_Other                            False\n",
       "primary_use_Parking                          False\n",
       "primary_use_Public services                  False\n",
       "primary_use_Religious worship                False\n",
       "primary_use_Retail                           False\n",
       "primary_use_Technology/science               False\n",
       "primary_use_Utility                          False\n",
       "site_id_2                                    False\n",
       "site_id_6                                    False\n",
       "site_id_7                                    False\n",
       "site_id_9                                    False\n",
       "site_id_10                                   False\n",
       "site_id_11                                   False\n",
       "site_id_13                                   False\n",
       "site_id_14                                   False\n",
       "site_id_15                                   False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "illustration.isnull().any() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the column names \n",
    "col_names = list(illustration.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meter_reading',\n",
       " 'square_feet',\n",
       " 'air_temperature',\n",
       " 'dew_temperature',\n",
       " 'month',\n",
       " 'day',\n",
       " 'primary_use_Education',\n",
       " 'primary_use_Entertainment/public assembly',\n",
       " 'primary_use_Food sales and service',\n",
       " 'primary_use_Healthcare',\n",
       " 'primary_use_Lodging/residential',\n",
       " 'primary_use_Manufacturing/industrial',\n",
       " 'primary_use_Office',\n",
       " 'primary_use_Other',\n",
       " 'primary_use_Parking',\n",
       " 'primary_use_Public services',\n",
       " 'primary_use_Religious worship',\n",
       " 'primary_use_Retail',\n",
       " 'primary_use_Technology/science',\n",
       " 'primary_use_Utility',\n",
       " 'site_id_2',\n",
       " 'site_id_6',\n",
       " 'site_id_7',\n",
       " 'site_id_9',\n",
       " 'site_id_10',\n",
       " 'site_id_11',\n",
       " 'site_id_13',\n",
       " 'site_id_14',\n",
       " 'site_id_15']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the column names will be changed such that\n",
    "# month_daz becomes a unit feature\n",
    "# primary use becomes a unit feature\n",
    "# site id becomes also a unit feature using ths Dataset API later\n",
    "# in the note book\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meter_reading                                float64\n",
       "square_feet                                    int64\n",
       "air_temperature                              float64\n",
       "dew_temperature                              float64\n",
       "month                                          int64\n",
       "day                                            int64\n",
       "primary_use_Education                          int64\n",
       "primary_use_Entertainment/public assembly      int64\n",
       "primary_use_Food sales and service             int64\n",
       "primary_use_Healthcare                         int64\n",
       "primary_use_Lodging/residential                int64\n",
       "primary_use_Manufacturing/industrial           int64\n",
       "primary_use_Office                             int64\n",
       "primary_use_Other                              int64\n",
       "primary_use_Parking                            int64\n",
       "primary_use_Public services                    int64\n",
       "primary_use_Religious worship                  int64\n",
       "primary_use_Retail                             int64\n",
       "primary_use_Technology/science                 int64\n",
       "primary_use_Utility                            int64\n",
       "site_id_2                                      int64\n",
       "site_id_6                                      int64\n",
       "site_id_7                                      int64\n",
       "site_id_9                                      int64\n",
       "site_id_10                                     int64\n",
       "site_id_11                                     int64\n",
       "site_id_13                                     int64\n",
       "site_id_14                                     int64\n",
       "site_id_15                                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data set dtypes\n",
    "illustration.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data types of the data set \n",
    "# this is important for converting the data set into tensorflow equivalent data set\n",
    "# note the data types for the incoming data should be carefully converted to\n",
    "# it tensorflow type to avoid errors\n",
    "data_types = list(illustration.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data types to \n",
    "# tensorflow data types \n",
    "for i,j in enumerate(data_types):\n",
    "    j = str(j) # convertr from numpy dtype to str\n",
    "    #print(j)\n",
    "    if j == 'float64':\n",
    "        data_types[i] = tf.float64\n",
    "    else:\n",
    "        data_types[i]  = tf.int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tf.float64, tf.int32, tf.float64, tf.float64]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data types are now in tensrfloe data types\n",
    "data_types[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate train and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate test train\n",
    "partition= 1000\n",
    "illustration_test = illustration.head(partition).copy(deep=True)\n",
    "illustration_train = illustration[partition:].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to csv\n",
    "# note the index set to false and we dont need the header\n",
    "# it is this new csv that goes into the pipeline\n",
    "illustration_test.to_csv('illustration_test.csv',index=False,header=None)\n",
    "illustration_train.to_csv('illustration_train.csv',index=False,header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with downloaded csv to preserve data type\n",
    "Load the csv file and parse the data types of the datatset together into the\n",
    "tensorflow load pipeline\n",
    "\n",
    "This is as demonstrated in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data using the tensorflow Dataset API\n",
    "# add the data types too\n",
    "# the data types are tensorflow data types (see cell above)\n",
    "csvData = tf.data.experimental.CsvDataset('illustration_train.csv', data_types, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(<tf.Tensor: id=46, shape=(), dtype=float64, numpy=-223.16063515656919>, <tf.Tensor: id=47, shape=(), dtype=int32, numpy=128536>, <tf.Tensor: id=48, shape=(), dtype=float64, numpy=-0.6938878093609953>, <tf.Tensor: id=49, shape=(), dtype=float64, numpy=0.3053940754239157>, <tf.Tensor: id=50, shape=(), dtype=int32, numpy=1>, <tf.Tensor: id=51, shape=(), dtype=int32, numpy=1>, <tf.Tensor: id=52, shape=(), dtype=int32, numpy=1>, <tf.Tensor: id=53, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=54, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=55, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=56, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=57, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=58, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=59, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=60, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=61, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=62, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=63, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=64, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=65, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=66, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=67, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=68, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=69, shape=(), dtype=int32, numpy=1>, <tf.Tensor: id=70, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=71, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=72, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=73, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=74, shape=(), dtype=int32, numpy=0>)]\n"
     ]
    }
   ],
   "source": [
    "# check the data type :\n",
    "print(list(csvData.take(1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the data and\n",
    "# merging the columns:\n",
    "# ---- day and month as single column\n",
    "# ---- merge the site id as a single feature vector vector\n",
    "# ---- primary use as a single feature vector\n",
    "\n",
    "# take the forst 4 col names that meter reading, square feet, air temp , dew temp,\n",
    "# add it to a the new column names that would be formed after single column merging\n",
    "\n",
    "\n",
    "\n",
    "# define new column names from the previous data set col_names\n",
    "# the new col names will be used in the tensorflow API\n",
    "# col_names = meter reading ,col_names[1]=sqaure feet,col_names[2] = air temperature\n",
    "# col_names[3] = dew temperature\n",
    "col_names_= [col_names[0],col_names[1],col_names[2],col_names[3],'month_day','primary_use','site_id' ]\n",
    "\n",
    "def _parse_csv_row(*vals):\n",
    "    '''\n",
    "    Uses Feature columns\n",
    "    Does feature engineering\n",
    "    '''\n",
    "    \n",
    "    # month and day and single feature\n",
    "    # the 4:6 implies take column 4 and 5\n",
    "    # which corresponds to month and day\n",
    "    month_day = tf.convert_to_tensor(vals[4:6])\n",
    "    # primary use as single feature\n",
    "    # the 6:20 implies take column 6 to 19\n",
    "    # this is where the primary use is\n",
    "    primary_use = tf.convert_to_tensor(vals[6:20])\n",
    "    # site id as single feature\n",
    "    # the 20:29 implies take column 20 to 29\n",
    "    # this is the site id\n",
    "    site_id =  tf.convert_to_tensor(vals[20:29])\n",
    "    \n",
    "    # merge the features together, note meter reading is the fist column\n",
    "    # so it is excluded -- meaning index starts from 1\n",
    "    # 1 to 4 are sqaure feet, air temp, dew temperature respectively\n",
    "    # the others are as defined above\n",
    "    feature_vals = vals[1:4] + (month_day,primary_use,site_id)\n",
    "    \n",
    "    \n",
    "    # dictionaryof col names and  feature sets pair\n",
    "    features = dict(zip(col_names_[1:],feature_vals))\n",
    "    \n",
    "    # name the targets or lables\n",
    "    # meter reading is the tarhet\n",
    "    targets_tensor = tf.convert_to_tensor(vals[0],name=col_names_[0]) \n",
    "    \n",
    "    \n",
    "    \n",
    "    return features, targets_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Batch the datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the parser to the data set we loaded for training\n",
    "# csvData = loaded data above, _parse_csv_row = function above\n",
    "# feel free to change batch size\n",
    "dataset = csvData.map(_parse_csv_row).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'square_feet': <tf.Tensor: id=132, shape=(64,), dtype=int32, numpy=\n",
      "array([128536,  56137, 155882, 492898,  44784, 130577,  45086, 393530,\n",
      "       119262, 153999, 193723, 301307, 282152, 193960, 186572, 426472,\n",
      "        59498, 258491,  52357,  34819, 167055, 122122, 166395, 168696,\n",
      "        82939,  57811,  51483, 428647, 108392,  46230,  77632,  38173,\n",
      "       173479, 121146,   4482,  94751,  67377,   4607, 109263, 186840,\n",
      "        84346,  68030,  93206, 127632, 230747, 305000, 194111,  89858,\n",
      "        19454,  80438,  14185, 207115, 100813, 122922,  58377, 287594,\n",
      "       305047, 105167,  47578,  70852,  32256, 157545, 131745,  71936],\n",
      "      dtype=int32)>, 'air_temperature': <tf.Tensor: id=127, shape=(64,), dtype=float64, numpy=\n",
      "array([ -0.69388781,  -0.69388781,  -0.69388781,  -0.69388781,\n",
      "        -0.69388781,  -0.69388781,  -0.69388781,  -0.69388781,\n",
      "        -0.69388781,  -0.69388781,  -0.69388781,  -0.69388781,\n",
      "        -0.69388781,  -0.69388781,  -0.69388781,  -0.69388781,\n",
      "        -0.69388781,  -0.69388781,  -0.69388781,  -0.69388781,\n",
      "        -0.69388781,  -0.69388781,  -0.69388781,  -0.69388781,\n",
      "        -0.69388781,  -0.69388781,  -0.69388781,  -0.69388781,\n",
      "        -0.69388781,  -0.69388781,  -0.69388781,  -0.69388781,\n",
      "       -10.13768623, -10.13768623, -10.13768623, -10.13768623,\n",
      "       -10.13768623, -10.13768623, -10.13768623, -10.13768623,\n",
      "       -10.13768623,   1.50399912,   1.50399912,   1.50399912,\n",
      "        -0.1820888 ,  -0.1820888 ,  -0.1820888 ,  -0.1820888 ,\n",
      "        -0.1820888 ,  -0.1820888 ,  -0.1820888 ,  -0.1820888 ,\n",
      "        -0.1820888 ,  -0.1820888 ,  -0.1820888 ,  -0.1820888 ,\n",
      "        -0.1820888 ,  -0.1820888 ,  -0.1820888 ,  -0.1820888 ,\n",
      "        -0.1820888 ,  -0.1820888 ,  -0.1820888 ,  -0.1820888 ])>, 'dew_temperature': <tf.Tensor: id=128, shape=(64,), dtype=float64, numpy=\n",
      "array([ 0.30539408,  0.30539408,  0.30539408,  0.30539408,  0.30539408,\n",
      "        0.30539408,  0.30539408,  0.30539408,  0.30539408,  0.30539408,\n",
      "        0.30539408,  0.30539408,  0.30539408,  0.30539408,  0.30539408,\n",
      "        0.30539408,  0.30539408,  0.30539408,  0.30539408,  0.30539408,\n",
      "        0.30539408,  0.30539408,  0.30539408,  0.30539408,  0.30539408,\n",
      "        0.30539408,  0.30539408,  0.30539408,  0.30539408,  0.30539408,\n",
      "        0.30539408,  0.30539408, -0.83850438, -0.83850438, -0.83850438,\n",
      "       -0.83850438, -0.83850438, -0.83850438, -0.83850438, -0.83850438,\n",
      "       -0.83850438, -0.67134226, -0.67134226, -0.67134226, -0.61172453,\n",
      "       -0.61172453, -0.61172453, -0.61172453, -0.61172453, -0.61172453,\n",
      "       -0.61172453, -0.61172453, -0.61172453, -0.61172453, -0.61172453,\n",
      "       -0.61172453, -0.61172453, -0.61172453, -0.61172453, -0.61172453,\n",
      "       -0.61172453, -0.61172453, -0.61172453, -0.61172453])>, 'month_day': <tf.Tensor: id=129, shape=(64, 2), dtype=int32, numpy=\n",
      "array([[1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1]], dtype=int32)>, 'primary_use': <tf.Tensor: id=130, shape=(64, 14), dtype=int32, numpy=\n",
      "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'site_id': <tf.Tensor: id=131, shape=(64, 9), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0]], dtype=int32)>}, <tf.Tensor: id=133, shape=(64,), dtype=float64, numpy=\n",
      "array([-2.23160635e+02, -2.76535192e+01,  5.10360327e-01,  9.40156680e+01,\n",
      "       -7.49339046e+00,  1.30272205e+02,  3.42090721e+00, -1.38325753e+02,\n",
      "        1.63039614e+01, -2.04951451e+01, -5.95868579e+01, -1.22253399e+02,\n",
      "        6.80838073e+01,  5.46105359e-01, -7.15585031e+01, -3.24266660e+01,\n",
      "        1.05653859e+01,  1.56999558e+01, -6.59059800e+01,  0.00000000e+00,\n",
      "       -2.44097336e+02,  7.45993566e+01, -1.42633342e+02,  2.51486552e+00,\n",
      "        4.75941688e-01, -9.45801718e+00, -1.95700403e+01,  8.74804060e+02,\n",
      "       -3.24347867e+00,  1.93512758e+00,  3.26520846e+01, -6.07046629e+01,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00, -3.20411290e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "       -4.12613773e+01,  0.00000000e+00,  2.43151247e+01,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  2.76372733e+01,\n",
      "       -2.61836690e+00,  3.82016427e+01,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])>)]\n"
     ]
    }
   ],
   "source": [
    "# print to view  data set now \n",
    "# now the names correspond\n",
    "print(list(dataset.take(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorising ths features using feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature columns for primary use\n",
    "primary_use = tf.feature_column.numeric_column('primary_use', shape=(14,))\n",
    "# feature columns for site id\n",
    "site_id = tf.feature_column.numeric_column('site_id', shape=(9,))\n",
    "# month day feature columns\n",
    "month_day = tf.feature_column.numeric_column('month_day', shape=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the columns 1 to 4 are numeric -- square feet, air temp, dew temp\n",
    "numeric_columns = [tf.feature_column.numeric_column(feat) for feat in col_names_[1:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring together the feature columns defined above\n",
    "columns = numeric_columns + [month_day,primary_use,site_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make a keras  layer from the feature columns\n",
    "feature_layer = tf.keras.layers.DenseFeatures(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model layer \n",
    "model = tf.keras.Sequential([\n",
    "    feature_layer,\n",
    "    tf.keras.layers.Dense(16),\n",
    "    tf.keras.layers.Dense(8),\n",
    "    tf.keras.layers.Dense(4,activation='relu'),\n",
    "    tf.keras.layers.Dense(2),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer =tf.train.AdamOptimizer(),\n",
    "             loss='mse',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 113780.3749 - acc: 0.1953\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 79129.3159 - acc: 0.0562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f004c67c4d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epochs = 3 # increase this to train data better\n",
    "# for loop trains incrementally\n",
    "# this is discussed here https://github.com/keras-team/keras/issues/4446\n",
    "for i in range(train_epochs):    \n",
    "        model.fit(dataset,epochs=2,steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = tf.data.experimental.CsvDataset('illustration_test.csv', data_types, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = testdata.map(_parse_csv_row).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     16/Unknown - 0s 20ms/step - loss: 74641.3273 - acc: 0.3020"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a completely education series . Not to be used in production."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Work On Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving And Loading Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Salient Point about Tensor variables</b></p>\n",
    "\n",
    "    * We use variables to hold and update parameters. Variables are in-memory buffers containing tensors.\n",
    "    * Variable initializers must be run explicitly before other ops in the model can be run.\n",
    "    * The easiest way to do that is to add an op that initialize all variables before operation.\n",
    "    * They must be explicitly initialized and can be saved to disk during and after training. \n",
    "    * You can later restore saved values to exercise or analyze the model.\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of variable v1:  [23]\n",
      "Value of variable v2:  [3]\n",
      "Model saved in file: model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "\n",
    "# Create some variables.\n",
    "v1 = tf.Variable([23], name=\"v1\")\n",
    "v2 = tf.Variable([3], name=\"v2\")\n",
    "\n",
    "\n",
    "# Add an op to initialize the variables.\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# Saver to be able to restore a model\n",
    "saver = tf.train.Saver()\n",
    "save_dir = 'model/'\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "# Later, launch the model, initialize the variables, do some work, save the\n",
    "# variables to disk.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op) # initialise global variables\n",
    "    \n",
    "    # Do some work with the model.\n",
    "    print \"Value of variable v1: \",sess.run(v1); # print value of the variables\n",
    "    print \"Value of variable v2: \",sess.run(v2) ; # print value of variables\n",
    "    #Save the variables to disk.\n",
    "    saver.save(sess, \"model/model1\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Restoring Variables </b></p>\n",
    "\n",
    "The same Saver object is used to restore variables. We use the variable that we have stored in actual computation initialization.\n",
    "\n",
    "<p>Note that variable <i> v3</i> and<i> v4</i> are compuated from the saved variable above. </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable_v3  Computation yields  [26]\n",
      "variable_v4  Compuation yields  [20]\n"
     ]
    }
   ],
   "source": [
    "v3 = tf.add(v1,v2,\"variable_v3\")\n",
    "v4 = tf.subtract(v1,v2,\"variable_v4\")\n",
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(save_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        \n",
    "        print v3.name[0:11], \" Computation yields \", sess.run(v3) # v3.name[0:11] returns substring that bears pnly \n",
    "                                                                  # the name of substring\n",
    "        print v4.name[0:11],\" Compuation yields \", v4.eval()\n",
    "    else:\n",
    "        print('Oops, cannot load the model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<p><b>Saving variables reduce the computation load when we build complex models. It might be a very useful trick.</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python2]",
   "language": "python",
   "name": "Python [python2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice for GPU and Use of TF.SLIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> For GPU simply specify the device. As it can be observed below there is the option to use \n",
    "GPU or CPU</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "# Creates a graph.\n",
    "with tf.device('/cpu:0'):\n",
    "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "  c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "# Creates a graph.\n",
    "with tf.device('/gpu:0'):\n",
    "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "  c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use  allow_soft_placement \n",
    " <p> Should the specified device not be available use the allow_soft_placement to ensure\n",
    " it defaults to any available node  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "# Creates a graph.\n",
    "with tf.device('/cpu:0'):\n",
    "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "  c = tf.matmul(a, b)\n",
    "# Creates a session with allow_soft_placement and log_device_placement set\n",
    "# to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using the Slim package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining variable\n",
    "weights = slim.variable('weights',\n",
    "                             shape=[10, 10, 3 , 3],\n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                             regularizer=slim.l2_regularizer(0.05),\n",
    "                             #reuse=True,\n",
    "                             device='/gpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:0\n"
     ]
    }
   ],
   "source": [
    "print(weights.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and regular variables in Slim\n",
    "#### Make model variables in slim package \n",
    "# Model Variables\n",
    "weights = slim.model_variable('weight',\n",
    "                              shape=[10, 10, 3 , 3],\n",
    "                              initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                              regularizer=slim.l2_regularizer(0.05),\n",
    "                              device='/gpu:0')\n",
    "model_variables = slim.get_model_variables()\n",
    "\n",
    "# Regular variables\n",
    "my_var = slim.variable('my_var',\n",
    "                       shape=[30,30,3,3],\n",
    "                       #initializer=tf.zeros_initializer()\n",
    "                      )\n",
    "regular_variables_and_model_variables = slim.get_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_variables) # model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'weight:0' shape=(10, 10, 3, 3) dtype=float32_ref>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_variables   # regular variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'weights:0' shape=(10, 10, 3, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'weight:0' shape=(10, 10, 3, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'my_var:0' shape=(30, 30, 3, 3) dtype=float32_ref>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_variables_and_model_variables  # regular and model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build convolution layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Convolution in tf.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = slim.conv2d(my_var, 128, [3, 3], scope='conv1_1') # convolution with slim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv1_1/Relu:0' shape=(30, 30, 3, 128) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net # see the convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'my_var:0' shape=(30, 30, 3, 3) dtype=float32_ref>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_var # my variable to be used as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Convolution output shape  is ', (30, 30, 3, 128))\n",
      "\n",
      "\n",
      "[[[  28.93692398   10.7195673     0.         ...,   30.05235672    0.            0.        ]\n",
      "  [  46.07234955    7.70915699    0.         ...,    0.            0.            0.        ]\n",
      "  [  16.22345352    0.            0.         ...,    0.            0.            0.        ]]\n",
      "\n",
      " [[  15.06083679   57.84450912    0.         ...,   43.14462662\n",
      "     18.08991241    0.        ]\n",
      "  [  42.63002777   78.63479614    0.         ...,    0.           49.88648605\n",
      "      0.        ]\n",
      "  [  25.13093185   57.33727646    0.         ...,    0.           39.67684937\n",
      "      0.        ]]\n",
      "\n",
      " [[  15.48501587   59.74223328    0.         ...,   44.54095459\n",
      "     18.81566811    0.        ]\n",
      "  [  43.94680786   81.18474579    0.         ...,    0.           51.65623474\n",
      "      0.        ]\n",
      "  [  25.93070221   59.19885254    0.         ...,    0.           41.04518127\n",
      "      0.        ]]\n",
      "\n",
      " ..., \n",
      " [[  26.08940315  107.18469238    0.         ...,   79.44909668\n",
      "     36.95952225    0.        ]\n",
      "  [  76.86611938  144.93301392    0.         ...,    0.           95.900177\n",
      "      0.        ]\n",
      "  [  45.92501068  105.73829651    0.         ...,    0.           75.25363159\n",
      "      0.        ]]\n",
      "\n",
      " [[  26.51358032  109.08238983    0.         ...,   80.84542084\n",
      "     37.68526077    0.        ]\n",
      "  [  78.18289185  147.48291016    0.         ...,    0.           97.66990662\n",
      "      0.        ]\n",
      "  [  46.72478485  107.5998764     0.         ...,    0.           76.62195587\n",
      "      0.        ]]\n",
      "\n",
      " [[   0.           87.86815643    0.         ...,   95.35661316\n",
      "    169.47915649    0.        ]\n",
      "  [  17.28201675   99.45316315    0.         ...,   44.08452606\n",
      "    223.48425293    0.        ]\n",
      "  [  33.78520584   96.78174591    0.         ...,    0.          143.07852173\n",
      "      0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True)) # create a session\n",
    "\n",
    "sess.run(tf.global_variables_initializer()) # initialise global variables\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    my_var_= np.arange(8100).reshape(30,30,3,3) # make variable to feed to my_var\n",
    "    \n",
    "    convolution=sess.run(net, feed_dict={my_var: my_var_})# run convolution net\n",
    "    \n",
    "    print(\"Convolution output shape  is \", convolution.shape)\n",
    "    print(\"\\n\")\n",
    "    print(convolution[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Operation : repeat and stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for multiple convolution loop, instead of this:\n",
    "\n",
    "<p>net = slim.conv2d(net, 256, [3, 3], scope='conv3_1')</p>\n",
    "<p>net = slim.conv2d(net, 256, [3, 3], scope='conv3_2')</p>\n",
    "<p>net = slim.conv2d(net, 256, [3, 3], scope='conv3_3')</p>\n",
    "<p>net = slim.max_pool2d(net, [2, 2], scope='pool2')</p>\n",
    "<p>Use this :</p>\n",
    "<p>\n",
    "net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = slim.repeat(net, 3, slim.conv2d, 128, [3, 3], scope='conv3')\n",
    "net = slim.max_pool2d(net, [2, 2], scope='pool2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'pool2/MaxPool:0' shape=(30, 15, 1, 128) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('repeated convolution and pool layer output shape  is ', (30, 15, 1, 128))\n",
      "\n",
      "\n",
      "[[[ 14.90907288  15.58975983  21.07088661 ...,  14.6812706   20.05348969\n",
      "     0.        ]]\n",
      "\n",
      " [[ 15.48785782  20.05633354   8.90880394 ...,  17.70003319  11.46362972\n",
      "     0.        ]]\n",
      "\n",
      " [[ 14.35120773  22.78635597   8.12516022 ...,  22.27364731  12.7917366\n",
      "     0.        ]]\n",
      "\n",
      " ..., \n",
      " [[ 22.40684319  35.17812347  12.29501343 ...,  34.45668793  19.77536201\n",
      "     0.        ]]\n",
      "\n",
      " [[ 26.25650787  36.48138046  11.01838493 ...,  38.84376526  19.45845985\n",
      "     0.        ]]\n",
      "\n",
      " [[ 27.58261681  25.97477531  12.69604969 ...,  16.76501083  11.35532188\n",
      "     0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer()) # initialise global variables\n",
    "\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    my_var_= np.arange(8100).reshape(30,30,3,3) # make variable to feed to my_var\n",
    "    \n",
    "    convolution=sess.run(net, feed_dict={my_var: my_var_})# run convolution net\n",
    "    \n",
    "    print(\"repeated convolution and pool layer output shape  is \", convolution.shape)\n",
    "    print(\"\\n\")\n",
    "    print(convolution[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stack  operation\n",
    "<p>slim.stack operator allows a caller to repeatedly apply the same operation </p>\n",
    "<p>with different arguments to create a stack or tower of layers. slim.stack also </p>\n",
    "</p>creates a new tf.variable_scope for each operation created. For example, a </p>\n",
    "simple way to create a Multi-Layer Perceptron (MLP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_stack = slim.stack(net, slim.fully_connected, [32, 64, 128], scope='fc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'pool2/MaxPool:0' shape=(30, 15, 1, 128) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 15, 1, 128)\n",
      "('repeated convolution , pool layer   and stacked full connected output shape  is ', (30, 15, 1, 128))\n",
      "\n",
      "\n",
      "[[[  4.23216581   2.04975176   0.         ...,   4.95490932   0.73523045\n",
      "     0.        ]]\n",
      "\n",
      " [[  2.58513737   1.35162556   2.74485016 ...,   5.63072109   0.           0.        ]]\n",
      "\n",
      " [[  2.59122324   1.58042955   1.35051274 ...,   7.29484463   0.06100845\n",
      "     0.        ]]\n",
      "\n",
      " ..., \n",
      " [[  4.20043468   2.72412586   2.04240131 ...,  11.6093235    0.           0.        ]]\n",
      "\n",
      " [[  6.1571722    4.36448002   5.0669136  ...,  11.89010239   0.           0.        ]]\n",
      "\n",
      " [[  5.46519947   7.07594013   5.87183571 ...,  11.75918865   1.83790112\n",
      "     0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer()) # initialise global variables\n",
    "\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    my_var_= np.arange(8100).reshape(30,30,3,3) # make variable to feed to my_var\n",
    "    \n",
    "    convolution=sess.run(net, feed_dict={my_var: my_var_})# run convolution net\n",
    "    #print(convolution.shape)\n",
    "    full_connected = sess.run(fully_connected_stack, feed_dict={net:convolution})\n",
    "    \n",
    "    print(\"repeated convolution , pool layer   and stacked full connected output shape  is \", full_connected.shape)\n",
    "    print(\"\\n\")\n",
    "    print(full_connected[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider this stacked convolution\n",
    " Verbose way:\n",
    "<p>net = slim.fully_connected(net, 32, scope='fc/fc_1')</p>\n",
    "<p>net = slim.fully_connected(net, 64, scope='fc/fc_2')</p>\n",
    "<p>net = slim.fully_connected(net, 128, scope='fc/fc_3')</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent, TF-Slim way using slim.stack:\n",
    "stacked_convolution = slim.stack(net, slim.conv2d, [(32, [3, 3]), (32, [1, 1]), (64, [3, 3]), (64, [1, 1])], scope='core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('repeated convolution , pool layer   and stacked full connected output shape  is ', (30, 15, 1, 64))\n",
      "\n",
      "\n",
      "[[ 0.          0.          0.7477169   0.13506943  0.9713673   0.\n",
      "   5.1420927   1.4078269   1.6295898   0.15620512  2.0037446   0.          0.\n",
      "   0.          0.          1.18696272  0.          0.          0.          0.\n",
      "   1.11823201  0.          0.          0.72954273  0.          0.\n",
      "   1.33379316  0.93567711  0.          1.49034071  0.43626654  0.38108742\n",
      "   0.          0.          2.00853372  1.92772484  0.68287849  0.04531655\n",
      "   2.12834167  0.          0.26476377  0.          0.80931449  1.23653197\n",
      "   0.          2.44665647  0.          0.          0.          0.84878552\n",
      "   0.          0.51374352  0.          0.11831701  1.56720352  0.23275542\n",
      "   0.          2.39716816  0.69503832  3.70868254  0.          0.10966003\n",
      "   0.          2.09749699]]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer()) # initialise global variables\n",
    "\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    my_var_= np.arange(8100).reshape(30,30,3,3) # make variable to feed to my_var\n",
    "    \n",
    "    convolution=sess.run(net, feed_dict={my_var: my_var_})# run convolution net\n",
    "    stacked_connected = sess.run(stacked_convolution, feed_dict={net:convolution})\n",
    "    \n",
    "    print(\"repeated convolution , pool layer   and stacked full connected output shape  is \", stacked_connected.shape)\n",
    "    print(\"\\n\")\n",
    "    print(stacked_connected[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scopes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using scope to reduce the amount of operation being conducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fequently use variable in a scope: padding and weight\n",
    "with slim.arg_scope([slim.conv2d], padding='SAME',\n",
    "                      weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                      weights_regularizer=slim.l2_regularizer(0.0005)\n",
    "                   ):\n",
    "    net = slim.conv2d(my_var, 64, [3, 3], scope='conv1')\n",
    "    net = slim.conv2d(net, 128, [3, 3], padding='VALID', scope='conv2')\n",
    "    net = slim.conv2d(net, 256, [3, 3], scope='conv3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('scope convolution__', (30, 28, 1, 256))\n",
      "\n",
      "\n",
      "[[[ 0.          0.          0.30117792 ...,  0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.46823403 ...,  0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.49150071 ...,  0.          0.          0.        ]]\n",
      "\n",
      " ..., \n",
      " [[ 0.          0.          0.81940919 ...,  0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.62286884 ...,  0.          0.          0.01223324]]\n",
      "\n",
      " [[ 0.01849812  0.          0.43253469 ...,  0.18174121  0.          0.01509733]]]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer()) # initialise global variables\n",
    "\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    my_var_= np.arange(8100).reshape(30,30,3,3) # make variable to feed to my_var\n",
    "    \n",
    "    #convolution=sess.run(net, feed_dict={my_var: my_var_})# run convolution net\n",
    "    scope_convolution = sess.run(net, feed_dict={my_var:my_var_})\n",
    "    \n",
    "    print(\"scope convolution__\", scope_convolution.shape)\n",
    "    print(\"\\n\")\n",
    "    print(scope_convolution[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
